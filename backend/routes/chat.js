// routes/chat.js
require('dotenv').config();             // Charge .env

const express = require('express');
const fs = require('fs');
const path = require('path');
const router = express.Router();

const { MongoClient } = require('mongodb');
const { OpenAI } = require('openai');
const { MongoDBAtlasVectorSearch } = require('@langchain/mongodb');
const { OpenAIEmbeddings } = require('@langchain/openai');

// 1) Initialise OpenAI
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// 2) Initialise et connecte le vectorStore
let vectorStore;
(async function initVectorStore() {
  try {
    const client = new MongoClient(process.env.MONGO_URI);
    await client.connect();
    console.log('‚úÖ MongoDB client connect√©');

    const db = client.db('task_manager');
    const coll = db.collection('code_chunks');

    const embedder = new OpenAIEmbeddings({ openAIApiKey: process.env.OPENAI_API_KEY });
    vectorStore = new MongoDBAtlasVectorSearch(embedder, {
      collection: coll,
      indexName: 'vector_index',
      textKey: 'pageContent',
      embeddingKey: 'embedding',
      primaryKey: '_id',
    });

    console.log('‚úÖ Vector Store pr√™t');
  } catch (err) {
    console.error('‚ùå Erreur initVectorStore:', err);
  }
})();

// Fonction pour traiter les data URLs d'images
function prepareImageForGPT4Vision(dataURL) {
  if (!dataURL) return null;
  
  // V√©rifier si c'est d√©j√† une data URL correcte
  if (dataURL.startsWith('data:image/')) {
    // Nous utiliserons la data URL telle quelle
    console.log('üì∏ Image au format data URL d√©tect√©e');
    return dataURL;
  }
  
  // Si c'est une URL HTTP, la retourner directement
  if (dataURL.startsWith('http://') || dataURL.startsWith('https://')) {
    console.log('üì∏ Image au format URL Web d√©tect√©e');
    return dataURL;
  }
  
  // Si ce n'est ni une data URL ni une URL Web, c'est probablement un format non support√©
  console.warn('‚ö†Ô∏è Format d\'image non reconnu');
  return null;
}

// Route /api/chat
router.post('/', async (req, res) => {
  try {
    console.log("===== D√âBUT TRAITEMENT REQU√äTE CHAT =====");
    const { message, history = [], imageData, modelChoice = 'gpt-4.1' } = req.body;
    
    console.log(`üì© Requ√™te re√ßue: ${message && message.length} caract√®res, mod√®le: ${modelChoice}`);
    console.log(`üìö ${history.length} messages dans l'historique`);
    
    // V√©rification et pr√©paration de l'image
    const hasImage = !!imageData;
    console.log(`üñºÔ∏è Image pr√©sente: ${hasImage}`, hasImage ? `(~${Math.round(imageData.length / 1024)}KB)` : '');
    
    let processedImageData = null;
    if (hasImage) {
      processedImageData = prepareImageForGPT4Vision(imageData);
      console.log(`üñºÔ∏è Image trait√©e: ${!!processedImageData}`);
    }
    
    // V√©rifier si le vectorStore est pr√™t
    if (!vectorStore) {
      return res.status(503).json({ error: 'Vector Store non pr√™t, patientez quelques instants' });
    }

    // 3) Recherche des 5 meilleurs chunks
    const docs = await vectorStore.similaritySearch(message, 5);
    const context = docs.map(d => d.pageContent).join('\n---\n');

    // 4) Charger le README.md au niveau de la racine du repo
    const readmePath = path.resolve(__dirname, '../../README.md');
    let readmeContent = '';
    try {
      readmeContent = fs.readFileSync(readmePath, 'utf8');
    } catch (err) {
      console.warn('‚ö†Ô∏è README non trouv√© ou illisible √†', readmePath, err.message);
    }

    // 5) Pr√©pare les messages
    const messages = [];

    // Instruction syst√®me
    messages.push({
      role: 'system',
      content: hasImage 
        ? 'Tu es un assistant qui aide √† analyser des images et du code. Examine attentivement l\'image et r√©ponds aux questions de l\'utilisateur. D√©cris exactement ce que tu vois dans l\'image.'
        : 'Tu es un assistant qui explique comme √† un enfant de 10 ans. Pour chaque erreur, indique toujours le fichier et la ligne. Explique pas √† pas chaque commande et fournis le code complet dans un bloc markdown avec le chemin du fichier. Utilise un langage simple et bienveillant.'
    });

    // Contexte global du README
    if (readmeContent) {
      messages.push({
        role: 'system',
        content: `CONTEXTE GLOBAL DU PROJET (README.md) :\n${readmeContent}`
      });
    }

    // Contexte des extraits pertinents
    messages.push({ role: 'system', content: `Extraits pertinents :\n${context}` });

    // Ajouter l'historique des messages
    if (Array.isArray(history)) {
      // S'assurer que les messages sont au bon format
      const formattedHistory = history.map(msg => ({
        role: msg.role,
        content: msg.content
      }));
      messages.push(...formattedHistory);
    }
    
    // CORRIGER LE FORMAT POUR LES MESSAGES AVEC IMAGES
    if (hasImage && processedImageData && modelChoice === 'gpt-4o') {
      // Format correct pour GPT-4o avec Vision
      console.log("üì∏ Ajout d'une image au message avec GPT-4o Vision");
      messages.push({
        role: 'user',
        content: [
          { type: "text", text: message || "Que vois-tu dans cette image?" },
          {
            type: "image_url",
            image_url: { 
              url: processedImageData,
              detail: "high" // Demander une analyse d√©taill√©e
            }
          }
        ]
      });
    } else {
      // Format standard pour les messages texte uniquement
      console.log("‚úâÔ∏è Ajout d'un message texte uniquement");
      messages.push({ role: 'user', content: message });
    }

    // D√©terminer le bon mod√®le √† utiliser
    const finalModel = hasImage ? 'gpt-4o' : modelChoice;
    console.log(`üöÄ Envoi √† l'API OpenAI avec le mod√®le: ${finalModel}`);
    
    // 6) Appel √† l'API d'OpenAI avec le mod√®le s√©lectionn√©
    const completion = await openai.chat.completions.create({
      model: finalModel,
      messages,
      temperature: 0.7,
      max_tokens: 2000
    });

    console.log(`‚úÖ R√©ponse re√ßue: ${completion.choices[0].message.content.length} caract√®res`);
    return res.json({ reply: completion.choices[0].message.content });
  } catch (err) {
    console.error('‚ùå Erreur chat d√©taill√©e:', err);
    
    // Pr√©parer un message d'erreur utilisateur
    let userErrorMessage = "Une erreur s'est produite lors du traitement de votre demande.";
    
    // V√©rifier si l'erreur est li√©e √† l'image
    if (err.message && (
        err.message.includes('image') || 
        err.message.includes('vision') || 
        err.message.includes('not supported')
    )) {
      userErrorMessage = "Erreur lors du traitement de l'image. Veuillez v√©rifier que l'image est valide et r√©essayer.";
    }
    
    return res.status(500).json({ 
      error: err.message,
      reply: userErrorMessage
    });
  }
});

module.exports = router;